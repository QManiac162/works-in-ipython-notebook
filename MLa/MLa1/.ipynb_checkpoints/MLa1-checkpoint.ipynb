{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85cf3c2d",
   "metadata": {},
   "source": [
    "NATURAL LANGUAGE PROCESSING: its a subfield of AI in which its depth involves the interactions between computers and humans. Humans communicate in words or in sentences and not in tables or spreadsheets as the computers do. Information human speak or write is unstructered and difficult for computer to interpret. In NLP, the goal is to make computers understand the unstructred text and retrieve meaningful pieces of information of information from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c71afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhumans perform NLP well but even we are not perfect as we often hear sentences with double m,eaning which \\nalways doesnt make sense in the current situation unless and untill we actually dwelve into the situation\\nor intake it in a different way.\\n\\nex1. I saw a man on a hill with a telescope.\\ninterpretations possible:\\nThere is a man on the hill, and I watched him with my telescope.\\nThere is a man on the hill, and he has a telescope.\\nI’m on a hill, and I saw a man using my telescope.\\nI’m on a hill, and I saw a man who has a telescope.\\nThere is a man on a hill, and I saw him something with my telescope.\\n\\nex2. Can you help me with the can?\\nIn the sentence above, we can see that there are two “can” words, but both of them have different meanings. \\nHere the first “can” word is used for question formation. The second “can” word at the end of the sentence \\nis used to represent a container that holds food or liquid.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#understandfing NLP:\n",
    "#Understanding is the intersection of the process of information revealed by someone and\n",
    "#listening by someone else\n",
    "'''\n",
    "humans perform NLP well but even we are not perfect as we often hear sentences with double m,eaning which \n",
    "always doesnt make sense in the current situation unless and untill we actually dwelve into the situation\n",
    "or intake it in a different way.\n",
    "\n",
    "ex1. I saw a man on a hill with a telescope.\n",
    "interpretations possible:\n",
    "There is a man on the hill, and I watched him with my telescope.\n",
    "There is a man on the hill, and he has a telescope.\n",
    "I’m on a hill, and I saw a man using my telescope.\n",
    "I’m on a hill, and I saw a man who has a telescope.\n",
    "There is a man on a hill, and I saw him something with my telescope.\n",
    "\n",
    "ex2. Can you help me with the can?\n",
    "In the sentence above, we can see that there are two “can” words, but both of them have different meanings. \n",
    "Here the first “can” word is used for question formation. The second “can” word at the end of the sentence \n",
    "is used to represent a container that holds food or liquid.\n",
    "\n",
    "'''\n",
    "#from examples we see that that language processing is not \"deterministic\" (i.e. the same language has \n",
    "#different interpretations) and something suitable to one person might not be suitable to another.\n",
    "#NLP has a non-deterministic approach, i.e. it can be used to create a new intelligent system that can \n",
    "#understand and interpret language in different situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf65a3fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNatural Language Processing is separated in two different approaches:\\n\\nRule-based Natural Language Processing:\\nIt uses common sense reasoning for processing tasks. For instance, the freezing temperature can lead to \\ndeath, or hot coffee can burn people’s skin, along with other common sense reasoning tasks. However, this \\nprocess can take much time, and it requires manual effort.\\n\\nStatistical Natural Language Processing:\\nIt uses large amounts of data and tries to derive conclusions from it. Statistical NLP uses machine \\nlearning algorithms to train NLP models. After successful training on large amounts of data, the trained \\nmodel will have positive outcomes with deduction.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Natural Language Processing is separated in two different approaches:\n",
    "\n",
    "Rule-based Natural Language Processing:\n",
    "It uses common sense reasoning for processing tasks. For instance, the freezing temperature can lead to \n",
    "death, or hot coffee can burn people’s skin, along with other common sense reasoning tasks. However, this \n",
    "process can take much time, and it requires manual effort.\n",
    "\n",
    "Statistical Natural Language Processing:\n",
    "It uses large amounts of data and tries to derive conclusions from it. Statistical NLP uses machine \n",
    "learning algorithms to train NLP models. After successful training on large amounts of data, the trained \n",
    "model will have positive outcomes with deduction.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f27bf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nComponents of Natural Language Processing (NLP):\\n\\na. Lexical Analysis:\\nWith lexical analysis, we divide a whole chunk of text into paragraphs, sentences, and words. It involves \\nidentifying and analyzing words’ structure.\\n\\nb. Syntactic Analysis:\\nSyntactic analysis involves the analysis of words in a sentence for grammar and arranging words in a \\nmanner that shows the relationship among the words. For instance, the sentence “The shop goes to the house”\\ndoes not pass.\\n\\nc. Semantic Analysis:\\nSemantic analysis draws the exact meaning for the words, and it analyzes the text meaningfulness. \\nSentences such as “hot ice-cream” do not pass.\\n\\nd. Disclosure Integration:\\nDisclosure integration takes into account the context of the text. It considers the meaning of the sentence\\nbefore it ends. For example: “He works at Google.” In this sentence, “he” must be referenced in the \\nsentence before it.\\n\\ne. Pragmatic Analysis:\\nPragmatic analysis deals with overall communication and interpretation of language. It deals with deriving \\nmeaningful use of language in various situations.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Components of Natural Language Processing (NLP):\n",
    "\n",
    "a. Lexical Analysis:\n",
    "With lexical analysis, we divide a whole chunk of text into paragraphs, sentences, and words. It involves \n",
    "identifying and analyzing words’ structure.\n",
    "\n",
    "b. Syntactic Analysis:\n",
    "Syntactic analysis involves the analysis of words in a sentence for grammar and arranging words in a \n",
    "manner that shows the relationship among the words. For instance, the sentence “The shop goes to the house”\n",
    "does not pass.\n",
    "\n",
    "c. Semantic Analysis:\n",
    "Semantic analysis draws the exact meaning for the words, and it analyzes the text meaningfulness. \n",
    "Sentences such as “hot ice-cream” do not pass.\n",
    "\n",
    "d. Disclosure Integration:\n",
    "Disclosure integration takes into account the context of the text. It considers the meaning of the sentence\n",
    "before it ends. For example: “He works at Google.” In this sentence, “he” must be referenced in the \n",
    "sentence before it.\n",
    "\n",
    "e. Pragmatic Analysis:\n",
    "Pragmatic analysis deals with overall communication and interpretation of language. It deals with deriving \n",
    "meaningful use of language in various situations.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada8ab64",
   "metadata": {},
   "source": [
    "# NLP libraries\n",
    "<font color=red>a. The NLTK Python framework is generally used as an education and research tool. It’s not usually used on  production applications. However, it can be used to build exciting programs due to its ease of use.</font><br>\n",
    "Features:\n",
    " - Tokenization.\n",
    " - Part Of Speech tagging (POS).\n",
    " - Named Entity Recognition (NER).\n",
    " - Classification.\n",
    " - Sentiment analysis.\n",
    " - Packages of chatbots.<br>\n",
    "\n",
    "Use-cases:\n",
    " - Recommendation systems.\n",
    " - Sentiment analysis.\n",
    " - Building chatbots.<br>\n",
    "\n",
    "<font color=red>b. spaCy:\n",
    "spaCy is an open-source natural language processing Python library designed to be fast and production-ready.spaCy focuses on providing software for production usage.</font><br>\n",
    "Features:\n",
    " - Tokenization.\n",
    " - Part Of Speech tagging (POS).\n",
    " - Named Entity Recognition (NER).\n",
    " - Classification.\n",
    " - Sentiment analysis.\n",
    " - Dependency parsing.\n",
    " - Word vectors.<br>\n",
    "\n",
    "Use-cases:\n",
    "<br>\n",
    " - Autocomplete and autocorrect.\n",
    " - Analyzing reviews.\n",
    " - Summarization.<br>\n",
    " \n",
    "<font color=red>c. Gensim:\n",
    "Gensim is an NLP Python framework generally used in topic modeling and similarity detection. It is not a general-purpose NLP library, but it handles tasks assigned to it very well.</font><br>\n",
    "\n",
    "Features:\n",
    " - Latent semantic analysis.\n",
    " - Non-negative matrix factorization.\n",
    " - TF-IDF.<br>\n",
    "\n",
    "Use-cases:\n",
    " - Converting documents to vectors.\n",
    " - Finding text similarity.\n",
    " - Text summarization.<br>\n",
    "\n",
    "<font color=red>d. Pattern:\n",
    "Pattern is an NLP Python framework with straightforward syntax. It’s a powerful tool for scientific and \n",
    "non-scientific tasks. It is highly valuable to students.</font><br>\n",
    "\n",
    "Features:\n",
    " - Tokenization.\n",
    " - Part of Speech tagging.\n",
    " - Named entity recognition.\n",
    " - Parsing.\n",
    " - Sentiment analysis.<br>\n",
    "\n",
    "Use-cases:\n",
    " - Spelling correction.\n",
    " - Search engine optimization.\n",
    " - Sentiment analysis.<br>\n",
    "\n",
    "<font color=red>e. TextBlob:\n",
    "TextBlob is a Python library designed for processing textual data.</font><br>\n",
    "\n",
    "Features:\n",
    " - Part-of-Speech tagging.\n",
    " - Noun phrase extraction.\n",
    " - Sentiment analysis.\n",
    " - Classification.\n",
    " - Language translation.\n",
    " - Parsing.\n",
    " - Wordnet integration.<br>\n",
    "\n",
    "Use-cases:\n",
    " - Sentiment Analysis.\n",
    " - Spelling Correction.\n",
    " - Translation and Language Detection.<br>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2019b2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting basic.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile basic.txt\n",
    "Once upon a time there was an old mother pig who had three little pigs and not enough food to feed them. So when they were old enough, she sent them out into the world to seek their fortunes.\n",
    "\n",
    "The first little pig was very lazy. He didn't want to work at all and he built his house out of straw. The second little pig worked a little bit harder but he was somewhat lazy too and he built his house out of sticks. Then, they sang and danced and play ed together the rest of the day.\n",
    "\n",
    "The third little pig worked hard all day and built his house with bricks. It was a sturdy house complete with a fine fireplace and chimney. It looked like it could withstand the strongest winds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e69edf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> \n",
      " Once upon a time there was an old mother pig who had three little pigs and not enough food to feed them. So when they were old enough, she sent them out into the world to seek their fortunes.\n",
      "\n",
      "The first little pig was very lazy. He didn't want to work at all and he built his house out of straw. The second little pig worked a little bit harder but he was somewhat lazy too and he built his house out of sticks. Then, they sang and danced and play ed together the rest of the day.\n",
      "\n",
      "The third little pig worked hard all day and built his house with bricks. It was a sturdy house complete with a fine fireplace and chimney. It looked like it could withstand the strongest winds.\n",
      " \n",
      " 677\n"
     ]
    }
   ],
   "source": [
    "#importing the sentences\n",
    "import pandas as pd\n",
    "text_file=open(\"basic.txt\")\n",
    "text=text_file.read()\n",
    "print(type(text),\"\\n\",text,\"\\n\",len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9b7123d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DEEP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 \n",
      " ['Once upon a time there was an old mother pig who had three little pigs and not enough food to feed them.', 'So when they were old enough, she sent them out into the world to seek their fortunes.', 'The first little pig was very lazy.', \"He didn't want to work at all and he built his house out of straw.\", 'The second little pig worked a little bit harder but he was somewhat lazy too and he built his house out of sticks.', 'Then, they sang and danced and play ed together the rest of the day.', 'The third little pig worked hard all day and built his house with bricks.', 'It was a sturdy house complete with a fine fireplace and chimney.', 'It looked like it could withstand the strongest winds.']\n"
     ]
    }
   ],
   "source": [
    "#importing the lib\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "\n",
    "#sentence tokenizing: by tokenizing text with sent_tokenize(), we can get text as sentences\n",
    "sentences=sent_tokenize(text)\n",
    "print(len(sentences),\"\\n\",sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93b75f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 \n",
      " ['Once', 'upon', 'a', 'time', 'there', 'was', 'an', 'old', 'mother', 'pig', 'who', 'had', 'three', 'little', 'pigs', 'and', 'not', 'enough', 'food', 'to', 'feed', 'them', '.', 'So', 'when', 'they', 'were', 'old', 'enough', ',', 'she', 'sent', 'them', 'out', 'into', 'the', 'world', 'to', 'seek', 'their', 'fortunes', '.', 'The', 'first', 'little', 'pig', 'was', 'very', 'lazy', '.', 'He', 'did', \"n't\", 'want', 'to', 'work', 'at', 'all', 'and', 'he', 'built', 'his', 'house', 'out', 'of', 'straw', '.', 'The', 'second', 'little', 'pig', 'worked', 'a', 'little', 'bit', 'harder', 'but', 'he', 'was', 'somewhat', 'lazy', 'too', 'and', 'he', 'built', 'his', 'house', 'out', 'of', 'sticks', '.', 'Then', ',', 'they', 'sang', 'and', 'danced', 'and', 'play', 'ed', 'together', 'the', 'rest', 'of', 'the', 'day', '.', 'The', 'third', 'little', 'pig', 'worked', 'hard', 'all', 'day', 'and', 'built', 'his', 'house', 'with', 'bricks', '.', 'It', 'was', 'a', 'sturdy', 'house', 'complete', 'with', 'a', 'fine', 'fireplace', 'and', 'chimney', '.', 'It', 'looked', 'like', 'it', 'could', 'withstand', 'the', 'strongest', 'winds', '.']\n"
     ]
    }
   ],
   "source": [
    "#word tokenizing: by tokenizing text with word_tokenize(), we can get text as words\n",
    "words=word_tokenize(text)\n",
    "print(len(words),\"\\n\",words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3662cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 9),\n",
       " ('and', 7),\n",
       " ('little', 5),\n",
       " ('a', 4),\n",
       " ('was', 4),\n",
       " ('pig', 4),\n",
       " ('the', 4),\n",
       " ('house', 4),\n",
       " ('to', 3),\n",
       " ('out', 3)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the frequency of distribution:\n",
    "from nltk.probability import FreqDist\n",
    "fdist=FreqDist(words)\n",
    "#to print say 10 most common words in the story\n",
    "fdist.most_common(10)\n",
    "#HEre it will also include the punctuation marks as well, and these are hardly required in the when we are\n",
    "#analogies of speech, and the punctuation marks only help in conveying the tone of the message, we often\n",
    "#need to seperate the punctuation from the real text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
